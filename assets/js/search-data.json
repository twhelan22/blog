{
  
    
        "post0": {
            "title": "Evaluating penalty takers using empirical Bayes estimation",
            "content": "Why do we assume every player is equally skilled from the penalty spot? . Last weekend there were two big penalty misses in the Premier league, one by Kevin De Bruyne against Liverpool and the other by Ademola Lookman against West Ham, both of which resulted in dropped points for their respective teams. It&#39;s rare to see two penalties that bad in the same weekend - in fact the last time someone completely missed the target from the spot in the Premier league also cost Manchester City three points against Liverpool! So why was Lookman even taking Fulham&#39;s penalty in the first place, and are City so bad at penalties that Ederson might actually be the best man for the job? . Trying to quantify finishing skill is not a new idea in the football analytics community, but penalties are usually an afterthought in the analysis (if they are considered at all). I&#39;ve seen plenty of posts about expected goals (I&#39;ve even written some), and the typical process of dealing with penalties is to just throw away the data and assume penalty xG = penalties taken * average conversion rate. I have been guilty of that myself, but are we really saying Gabriel Jesus (4/10 penalties scored) is just as good as Yaya Touré (15/15)? Is Touré the same as Matt Le Tissier (27/27)? There are plenty of &#39;best penalty takers of all time&#39; articles that suggest otherwise (1.16 million results on Google). We can do better. . Here are some typical reasons people give for ignoring finishing skill estimates: . On-ball data is noisy and we are missing key information about defender positions, whether the shot with the player&#39;s strong or weak foot and countless other variables. | The sample size of shots from any given location is small. | Even if we could find some signal in the noise, there probably isn&#39;t much difference between the best finisher and the worst anyway. | Whilst you might be able to get away with that line of thinking in general, it seems odd to apply that logic to penalties, since: . The most important concerns aren&#39;t a factor here; the main differences between one penalty and another are goalkeeper skill, pitch conditions, and (dare I say it!) confidence. We could make this process significantly more complicated by trying to account for those variables, but that might be overthinking things given what we&#39;re trying to accomplish. Unlike open-play shots a rocket into the top corner isn&#39;t necessarily better than a delicate chip down the middle (unless your name is Ademola Lookman!), so we can focus more on the results than the execution. If a club wanted to use this process to find their best penalty taker these variables could be controlled, for example by having a penalty shootout (pressure/competitive element) at the end of training (same goalkeeper/pitch conditions) to build up a large sample size of penalty shots for each player in the squad, so a simple model could be just as useful in practice as a more complex one. | We still won&#39;t have a huge sample size with penalties, but at least the shot location is fixed. | Intuitively we know there is at least some difference, so why don&#39;t we try to investigate further? | Empirical Bayes estimation . There are several methods we could use to create a penalty taking skill estimate, but by far the easiest is &#39;empirical Bayes estimation&#39;. . Important: This analysis is heavily inspired by David Robinson&#8217;s excellent post &#8217;Understanding empirical Bayes estimation (using baseball statistics)&#8217;. Since I prefer Python to R I&#8217;ll be replicating some of the steps he used but I won&#8217;t be going as in-depth, so I highly suggest reading through his post as well if you have time! . As you&#39;ll see in a moment we have data on penalties scored and penalties taken for different players, and we want to estimate penalty conversion rate (scored/taken). Robinson has shown that data in this form can be modelled using a beta distribution. In his words: . &quot;The beta distribution can be understood as representing a probability distribution of probabilities - that is, it represents all the possible values of a probability when we don’t know what that probability is.&quot; . In our case the probability we are looking to estimate is penalty conversion rate (or &#39;probability of a succesful penalty&#39;). Of course we could just take the actual rate, but that&#39;s not very useful in practice. Say John Smith has scored 3/3 penalties, do we really think he is incapable of missing? It would be preferable to ask &#39;what is our realistic best estimate of Smith&#39;s conversion rate given the fact that he has scored 3/3 so far?&#39; This method is known as &#39;Bayesian inference&#39;; we start with a prior estimate of conversion rate (e.g. the league average distribution) and update our estimate to reflect the new evidence we have on Smith (3/3 penalties scored). . Note: I&#8217;m not going to spend much time explaining Bayes&#8217; Theorem, so if you haven&#8217;t come across it before see here for a primer (or here for the short version). . In standard Bayesian inference we usually decide on the prior distribution ahead of time, but we can approximate this method by estimating the prior distribution from our data instead (hence &#39;empirical estimation&#39;). To obtain our prior we&#39;ll follow Robinson&#39;s method - fit a beta distribution to the data and use that as a starting point for each player or team&#39;s prediction. . Estimate a prior from the data . The main dataset we will be using is from FBRef&#39;s Big 5 European Leagues Stats page. Let&#39;s load it in now. . Note: I am ignoring goalkeeper skill for this analysis, but goalkeeper data is also available at FBRef if you want to repeat the steps to estimate penalty save percentage instead! If you aren&#8217;t familiar with Python I wrote an introductory series that you can check out here. . df = pd.read_csv(&#39;https://raw.githubusercontent.com/twhelan22/blog/master/data/big_five_penalties.csv&#39;, encoding=&#39;utf-8&#39;) df.head() . . name team league season penalties_scored penalties_taken . 0 Matt Le Tissier | Southampton | England | 1992 | 2 | 2 | . 1 Dean Saunders | Aston Villa | England | 1992 | 1 | 2 | . 2 Alan Shearer | Blackburn | England | 1992 | 3 | 3 | . 3 John Sheridan | Sheffield Weds | England | 1992 | 2 | 2 | . 4 Andy Sinton | QPR | England | 1992 | 1 | 2 | . The dataset contains penalty statistics for players in France, Germany, Italy, Spain and England&#39;s top division from the 92/93 season to November 2020. Whilst that sounds like a lot of data, most of the players have only taken a handful of penalties: . players = df.groupby(&#39;name&#39;)[[&#39;penalties_scored&#39;, &#39;penalties_taken&#39;]].sum().reset_index() def conversion_rate(df): df[&#39;conversion_rate&#39;] = df[&#39;penalties_scored&#39;] / df[&#39;penalties_taken&#39;] return conversion_rate(players) players.describe() . . penalties_scored penalties_taken conversion_rate . count 2204.00 | 2204.00 | 2204.00 | . mean 3.90 | 5.02 | 0.71 | . std 6.00 | 7.13 | 0.34 | . min 0.00 | 1.00 | 0.00 | . 25% 1.00 | 1.00 | 0.50 | . 50% 2.00 | 2.00 | 0.83 | . 75% 5.00 | 6.00 | 1.00 | . max 91.00 | 105.00 | 1.00 | . This means that over half of the players in the dataset have a conversion rate of 100% or 0%: . sns.displot(data=players, x=&#39;conversion_rate&#39;, kde=True); . . Clearly those players would add a lot of noise to our estimate, but we don&#39;t want to just throw out a big chunk of data if we can help it. To get around this problem, we can groupby &#39;team&#39; and fit a beta distribution to the resulting team-level data instead. We can then use that prior to get predictions for each player afterwards. . Note: If you have a bigger dataset you could use players to get the prior instead! . That looks much more reasonable already! Let&#39;s filter out teams with fewer than 10 attempts and see what we&#39;re left with. . This is what we&#39;d expect to see intuitively; most of the teams are close to the average, with a few teams having performed significantly better or worse than average. Let&#39;s try to fit a beta distribution to this data: . # Plot the distribution of actual conversion rate (our original data) palette = sns.color_palette() fig, ax = plt.subplots(figsize=(8,5)) ax.xaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1)) sns.kdeplot(data=teams_filt[&#39;conversion_rate&#39;]) # Fit a beta distribution to the data to get the alpha0 and beta0 parameters # Note that for this to work 0 &lt; data &lt; 1, which is OK in this case, # since a predicted conversion rate of 0% or 100% isn&#39;t realistic in practice alpha0, beta0, _, _ = ss.beta.fit(teams_filt[&#39;conversion_rate&#39;], floc=0, fscale=1) # Generate a beta distribution using alpha0 and beta0 (the prior distribution) prior_dist = ss.beta.rvs(alpha0, beta0, size=10000) # Plot the random beta distribution we just generated sns.kdeplot(data=prior_dist) # Add legend custom_lines = [Line2D([0], [0], color=palette[0], lw=2.5), Line2D([0], [0], color=palette[1], lw=2.5)] ax.legend(custom_lines, [&#39;Actual conversion rate&#39;, &#39;Random beta distribution: nalpha0={:.2f}, beta0={:.2f}&#39;.format(alpha0, beta0)]); . . That looks good enough for what we are trying to acomplish here! The beta distribution we just generated is defined as: . $X sim Beta( alpha_0, beta_0)$ . So what are $ alpha_0$ and $ beta_0$? In this case $ alpha_0$ = penalties scored and $ beta_0$ = penalties missed. With zero evidence we are going to start with the assumption that every player or team has scored $ alpha_0$ times and missed $ beta_0$ times. Our prior estimate of conversion rate is therefore: . $prior :estimate = frac{starting :goals}{starting :goals :+ :starting :misses} = frac{ alpha_0}{ alpha_0 :+ : beta_0}$ . We are essentially giving everyone a &#39;head start&#39; by assuming they have already taken some penalties and converted them at an average rate, which gets around the issue of small sample sizes. To incorporate the additional evidence we have for a particular player or team, we update their distribution as follows: . $Beta( alpha_0 :+ :goals, beta_0 :+ :misses)$ . Let&#39;s take a look at this in action to get a better understanding of the process. . Visualising the effects of empirical Bayes . # Define a function to get predicted conversion rate using alpha0 and beta0 def predicted_conversion(scored, taken, alpha=alpha0, beta=beta0): return (alpha0 + scored) / (alpha0 + beta0 + taken) prior = predicted_conversion(scored=0, taken=0) print(&#39;Start off with alpha0 = {:.2f} goals and beta0 = {:.2f} misses:&#39;.format(alpha0, beta0)) print(&#39;Prior estimate = {:.2f} / ({:.2f} + {:.2f}) = {:.2%} n&#39;.format(alpha0, alpha0, beta0, prior)) print(&#39;Then every time a penalty is taken, add the results to the starting estimate:&#39;) print(&#39;New estimate = (alpha0 + penalties_scored) / (alpha0 + beta0 + penalties_taken) n&#39;) sns.set(style=&#39;ticks&#39;) def plot_dist(scored, missed): taken = scored + missed new_estimate = predicted_conversion(scored=scored, taken=taken) # Plot the prior distribution fig, ax = plt.subplots(figsize=(9,6)) ax.set(title=&#39;After {:n} taken, {:n} scored: estimate = ({:.2f} + {:n}) / ({:.2f} + {:.2f} + {:n}) = {:.2%}&#39;.format(taken, scored, alpha0, scored, alpha0, beta0, taken, new_estimate), ylim=[0, 8], xlabel=&#39;Predicted penalty conversion rate&#39;) ax.xaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1)) sns.kdeplot(data=prior_dist, color=palette[-1], fill=True) plt.axvline(prior, 0, 0.95, color=palette[-1], linestyle=&#39;--&#39;) # Plot the new distribution new_dist = ss.beta.rvs(alpha0+scored, beta0+missed, size=10000) sns.kdeplot(data=new_dist, color=palette[3]) plt.axvline(new_estimate, 0, 0.95, color=palette[3], linestyle=&#39;--&#39;) # Add custom legend and axes custom_lines = [Line2D([0], [0], color=palette[3], lw=2.5), Line2D([0], [0], color=palette[-1], lw=2.5)] ax.legend(custom_lines, [&#39;New estimate: %s&#39; % (str(round(new_estimate*100, 2)))+&#39;%&#39;, &#39;Prior estimate: %s&#39; % (str(round(prior*100, 2)))+&#39;%&#39;], loc=&#39;upper left&#39;) sns.despine(right=True, top=True); plot_dist(1, 0) plot_dist(10, 1) . . Start off with alpha0 = 30.83 goals and beta0 = 8.82 misses: Prior estimate = 30.83 / (30.83 + 8.82) = 77.76% Then every time a penalty is taken, add the results to the starting estimate: New estimate = (alpha0 + penalties_scored) / (alpha0 + beta0 + penalties_taken) . After 1 taken, 1 scored our new estimate is very similar to the prior distribution - we don&#39;t want to make drastic changes after just one penalty! After 11 taken, 10 scored the new distribution is taller and narrower, since we are starting to get more confident in our estimate now we have more information. The new distribution has also shifted to the right, since we think it&#39;s more likely this player is above average. However, even with more evidence this player&#39;s predicted conversion rate of 80.61% is still closer to the average rate than the his actual conversion rate of 90.9%. . The process of pulling estimates back towards the average is sometimes referred to as &#39;shrinkage&#39;, which is illustrated more clearly in the interactive chart below. Teams with a small number of attempts are pulled back towards the prior estimate (the horizontal line) significantly, whereas teams with &gt; 150 attempts have a predicted conversion rate close to their actual conversion rate (i.e. close to the diagonal line). In other words, more evidence = less shrinkage, and vice versa. . teams = teams.assign(predicted_conversion=predicted_conversion(teams[&#39;penalties_scored&#39;], teams[&#39;penalties_taken&#39;])) # Set colour scheme to update automatically for each chart scheme = &#39;inferno&#39; col1 = matplotlib.colors.to_hex(sns.color_palette(scheme)[0]) col2 = matplotlib.colors.to_hex(sns.color_palette(scheme)[-1]) # Create an interactive scatter plot from teams showing predicted and actual conversion rate selection = alt.selection_single(on=&#39;mouseover&#39;); points = alt.Chart(teams).mark_circle(size=50).add_selection( selection ).encode( x=alt.X(&#39;conversion_rate&#39;, scale=alt.Scale(domain=(0.1, 1.1)), axis=alt.Axis(format=&#39;%&#39;, title=&#39;Actual conversion rate&#39;)), y=alt.X(&#39;predicted_conversion&#39;, scale=alt.Scale(domain=(0.685, 0.875)), axis=alt.Axis(format=&#39;%&#39;, title=&#39;Predicted conversion rate&#39;)), color=alt.condition(selection, &#39;penalties_taken:Q&#39;, alt.value(&#39;grey&#39;), legend=alt.Legend(title=&#39;Penalties taken&#39;), scale=alt.Scale(scheme=scheme)), opacity=alt.condition(selection, alt.value(0.8), alt.value(0.1)), tooltip=[&#39;team&#39;, &#39;penalties_scored&#39;, &#39;penalties_taken&#39;, alt.Tooltip(&#39;conversion_rate&#39;, format=&#39;.2%&#39;), alt.Tooltip(&#39;predicted_conversion&#39;, format=&#39;.2%&#39;)] ).interactive().properties( width=500, height=500, title=&#39;As the number of penalties taken increases, predicted rate approaches actual rate&#39; ) # Add horizontal line at y = alpha0 / (alpha0 + beta0) overlayh = pd.DataFrame({&#39;y&#39;: [prior]}) hline = alt.Chart(overlayh).mark_rule(color=col1, strokeWidth=2).encode(y=&#39;y:Q&#39;) overlayhtext = pd.DataFrame({&#39;x&#39;: [0.4], &#39;y&#39;: [prior], &#39;text&#39;: [&#39;Prior: y = alpha0 / (alpha0 + beta0)&#39;]}) htext = alt.Chart(overlayhtext).mark_text(color=col1, fontSize=15, baseline=&#39;bottom&#39;).encode(alt.X(&#39;x:Q&#39;), alt.Y(&#39;y:Q&#39;), alt.Text(&#39;text&#39;)) # Add diagonal line at y = x overlayd = pd.DataFrame({&#39;x&#39;: [-5, 0.7, 5], &#39;y&#39;: [-5, 0.7, 5], &#39;text&#39;: [&#39;&#39;, &#39;y = x&#39;, &#39;&#39;]}) dline = alt.Chart(overlayd).mark_line(color=col2, strokeWidth=2).encode(x=&#39;x:Q&#39;, y=&#39;y:Q&#39;) dtext = alt.Chart(overlayd).mark_text(color=col2, fontSize=15, angle=285, baseline=&#39;top&#39;).encode(alt.X(&#39;x:Q&#39;), alt.Y(&#39;y:Q&#39;), alt.Text(&#39;text&#39;)) alt.layer(points, hline, htext, dline, dtext ).configure_header( titleFontSize=20, titleFontWeight=&#39;normal&#39; ).configure_axis( labelFontSize=11, titleFontSize=14, titleFontWeight=&#39;normal&#39; ).configure_legend( labelFontSize=11, titleFontSize=12, titleFontWeight=&#39;normal&#39; ) . . Who are the best and worst penalty takers? . As we saw earlier, most players in the dataset have only taken a handful of penalties, and some of the players ranked worst in our new metric were players that happened to miss several times in their first few attempts. It might be more interesting to look at players who have taken at least 15 penalties (i.e. a team&#39;s main penalty taker for multiple seasons) instead. Let&#39;s start with the worst players in the dataset: . name penalties_scored penalties_taken conversion_rate predicted_conversion . 1330 Marek Hamšík | 7 | 15 | 46.67% | 69.22% | . 1309 Marco Di Vaio | 13 | 22 | 59.09% | 71.10% | . 1152 Kevin Phillips | 11 | 18 | 61.11% | 72.56% | . 125 Andrea Pirlo | 14 | 22 | 63.64% | 72.72% | . 1771 Roberto Baggio | 12 | 19 | 63.16% | 73.03% | . 2107 Wayne Rooney | 23 | 34 | 67.65% | 73.09% | . 501 Diego | 13 | 20 | 65.00% | 73.48% | . 1163 Klaas-Jan Huntelaar | 11 | 17 | 64.71% | 73.84% | . 1226 Luca Toni | 17 | 25 | 68.00% | 73.98% | . 650 Fernando Torres | 20 | 29 | 68.97% | 74.04% | . Some surprising names there perhaps! Pirlo consistently pops up on &#39;best penalty takers&#39; lists, but even if we look at his overall record on Transfermarkt we get a predicted conversion rate of just 74.5%. Roberto Baggio&#39;s career record, on the other hand, is much better than it looks here (83.2%). . Note: Transfermarkt&#8217;s league coverage isn&#8217;t exhaustive but I haven&#8217;t yet found a more comprehensive resource for penalty stats, so I will be using their &#8217;career&#8217; totals throughout the post to supplement the FBRef data. . What about the best players in the dataset? . name penalties_scored penalties_taken conversion_rate predicted_conversion . 1599 Olivier Monterrubio | 27 | 27 | 100.00% | 86.77% | . 1398 Matt Le Tissier | 24 | 24 | 100.00% | 86.15% | . 1825 Ryad Boudebouz | 20 | 20 | 100.00% | 85.22% | . 74 Alessandro Del Piero | 42 | 46 | 91.30% | 85.03% | . 371 Cristhian Stuani | 17 | 17 | 100.00% | 84.43% | . 609 Fabinho | 17 | 17 | 100.00% | 84.43% | . 1544 Nenê | 22 | 23 | 95.65% | 84.33% | . 382 Cristiano Ronaldo | 91 | 105 | 86.67% | 84.23% | . 544 Eden Hazard | 26 | 28 | 92.86% | 84.01% | . 1419 Max Kruse | 15 | 15 | 100.00% | 83.86% | . It&#39;s not surprising to see Le Tissier up there, since he is widely considered to be one of the best penalty takers ever. Rickie Lambert only took a few penalties in the Premiership, but he is at 87.24% over his career in all competitions. If you are following along in notebook form you can investigate different players below; some notable names that weren&#39;t in the dataset include goalkeeper Rogério Ceni (84.11%), Michel Platini (86.36%), Marco Van Basten (86.46%), Davor Suker (88.03%), Ferenc Puskás (88.19%), Ronald Koeman (89.54%) and Alan Shearer (89.86%, more on him later!). The best I&#39;ve found so far is Hugo Sánchez, who&#39;s 65/65 record puts him at 91.57%! . #@title Search for a player: { run: &quot;auto&quot;, vertical-output: true } text = &#39;Totti&#39; #@param {type:&quot;string&quot;} display(players[players[&#39;name&#39;].str.contains(text)]) # Alternative method (non-Colab Jupyter notebooks) def player_search(): text = widgets.Text() display(text) button = widgets.Button(description=&#39;Search&#39;) display(button) def on_button_clicked(b): return display(players[players[&#39;name&#39;].str.contains(text.value)]) button.on_click(on_button_clicked) . . name penalties_scored penalties_taken conversion_rate predicted_conversion . 684 Francesco Totti | 70 | 85 | 82.35% | 80.89% | . #@title Get predicted conversion rate: { run: &quot;auto&quot;, vertical-output: true } scored = 65 #@param {type:&quot;slider&quot;, min:0, max:150, step:1} missed = 0 #@param {type:&quot;slider&quot;, min:0, max:150, step:1} print(&#39;Scored:&#39;, scored, &#39;Missed:&#39;, missed) print(&#39;Predicted conversion rate: {:.2%}&#39;.format(predicted_conversion(scored, scored + missed))) # Alternative method (non-Colab Jupyter notebooks) def player_slider(): def slider(scored, missed): print(&#39;Scored:&#39;, scored, &#39;Missed:&#39;, missed) print(&#39;Predicted conversion rate: {:.2%}&#39;.format(predicted_conversion(scored, scored + missed))) interact(slider, scored=widgets.IntSlider(min=0, max=150, step=1, value=65), missed=widgets.IntSlider(min=0, max=150, step=1, value=0)) . . Scored: 65 Missed: 0 Predicted conversion rate: 91.57% . You might have noticed that this is a rare top ten list without Messi, and in the past he has even been called out for being &#39;phenomenally bad&#39; at penalties. Let&#39;s check whether that criticism was warranted. . Is Lionel Messi &#39;phenomenally bad&#39; at penalties? . Pretty average, actually. . # Initialise the plot fig, ax = plt.subplots(figsize=(9,6)) ax.set(title=&#39;Lionel Messi, Mr. Average&#39;, ylim=[0, 13], xlabel=&#39;Predicted penalty conversion rate&#39;) ax.xaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1)) # Generate a beta distribution representing the range of estimates for an average player sns.kdeplot(data=prior_dist, color=&#39;maroon&#39;, fill=True, bw_adjust=3) plt.axvline(prior, 0, 0.95, c=&#39;maroon&#39;, linestyle=&#39;--&#39;) # Generate a beta distribution representing the range of estimates for Messi # Note - using career numbers from Transfermarkt # https://www.transfermarkt.com/lionel-messi/elfmetertore/spieler/28003 goals = 97 misses = 26 messi_dist = ss.beta.rvs(alpha0+goals, beta0+misses, size=10000) sns.kdeplot(data=messi_dist, color=&#39;mediumblue&#39;, fill=True, bw_adjust=3) est1 = predicted_conversion(goals, goals+misses) plt.axvline(est1, 0, 0.95, c=&#39;mediumblue&#39;) # Add custom legend and axes custom_lines = [Line2D([0], [0], color=&#39;mediumblue&#39;, lw=2.5), Line2D([0], [0], color=&#39;maroon&#39;, lw=2.5, linestyle=&#39;--&#39;)] ax.legend(custom_lines, [&#39;Messi: %s&#39; % (str(round(est1*100, 1)))+&#39;%&#39;, &#39;Prior: %s&#39; % (str(round(prior*100, 1)))+&#39;%&#39;], loc=&#39;upper left&#39;) sns.despine(right=True, top=True); . . The beta distribution for our prior estimate is shown in red, with Messi&#39;s beta distribution in blue. . Tip: Definitely make your charts look worse by using Barcelona colours! . The distribution for Messi is taller and narrower than the prior distribution. This is because we have 123 penalty attempts for Messi, whereas our prior distribution starts off with a lot less, so we are more confident in Messi&#39;s prediction. We can also see that whilst Messi isn&#39;t &#39;phenomenally bad&#39; at penalties, in this case we may have found something he doesn&#39;t excel at. . Are Manchester City bad at penalties? . # Filter to the start of the 16/17 season teams_since_16 = df[df[&#39;season&#39;]&gt;2016].groupby(&#39;team&#39;)[[&#39;penalties_scored&#39;, &#39;penalties_taken&#39;]].sum().reset_index() conversion_rate(teams_since_16) teams_since_16 = teams_since_16.assign(predicted_conversion=predicted_conversion(teams_since_16[&#39;penalties_scored&#39;], teams_since_16[&#39;penalties_taken&#39;])) def percentile(all_scores, score): return round(ss.stats.percentileofscore(all_scores, score), 1) city_pct = percentile(teams_since_16[&#39;penalties_taken&#39;], teams_since_16.set_index(&#39;team&#39;).loc[&#39;Manchester City&#39;, &#39;penalties_taken&#39;]) print(&#39;Manchester City have taken more penalties than &#39;+str(city_pct)+&quot;% of teams nin Europe&#39;s big five leagues since 16/17. However...&quot;) . . Manchester City have taken more penalties than 84.5% of teams in Europe&#39;s big five leagues since 16/17. However... . palette = sns.color_palette() score = teams_since_16.set_index(&#39;team&#39;).loc[&#39;Manchester City&#39;, &#39;predicted_conversion&#39;] worse_or_equal = teams_since_16[teams_since_16[&#39;predicted_conversion&#39;]&lt;=score] worse_teams = len(worse_or_equal) - 1 # Create the main plot fig, ax = plt.subplots(figsize=(10,7)) ax.set(title=&quot;Since Pep Guardiola took charge in 16/17, only %d teams in Europe&#39;s big five leagues nhave a worse predicted penalty conversion rate than Manchester City&quot; % (worse_teams), ylim=[0, 20], xlabel=&#39;Predicted penalty conversion rate&#39;) ax.xaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1)) sns.kdeplot(data=teams_since_16[&#39;predicted_conversion&#39;], color=&#39;skyblue&#39;, fill=True) plt.axvline(teams_since_16[&#39;predicted_conversion&#39;].mean(), 0, 20, c=&#39;skyblue&#39;, linestyle=&#39;--&#39;) lineheight = 0.65*teams_since_16[teams_since_16[&#39;team&#39;]==&#39;Manchester City&#39;][&#39;penalties_taken&#39;].values[0]/teams_since_16[&#39;penalties_taken&#39;].max() textheight = 20.5*lineheight plt.axvline(score, 0, lineheight, c=palette[0]) plt.text(score, textheight, &#39;Manchester City&#39;, c=palette[0], ha=&#39;right&#39;) # Add rug - https://seaborn.pydata.org/generated/seaborn.rugplot.html#seaborn.rugplot sns.rugplot(data=teams_since_16[&#39;predicted_conversion&#39;], color=&#39;skyblue&#39;, height=0.035) # Add legend custom_lines = [Line2D([0], [0], color=palette[0], lw=2.5), Line2D([0], [0], color=&#39;skyblue&#39;, lw=2.5, linestyle=&#39;--&#39;), Line2D([0], [0], color=&#39;skyblue&#39;, lw=2.5)] ax.legend(custom_lines, [&#39;Manchester City: %s&#39; % (str(round(score*100, 1))+&#39;%&#39;), &#39;Average Team: %s&#39; % (str(round(teams_since_16[&#39;predicted_conversion&#39;].mean()*100, 1))+&#39;%&#39;), &#39;%d total teams&#39; % (len(teams_since_16))]) # Remove axes sns.despine(right=True, top=True); . . team penalties_scored penalties_taken conversion_rate predicted_conversion . 73 Manchester City | 16 | 25 | 64.00% | 72.44% | . 107 Stoke City | 0 | 3 | 0.00% | 72.29% | . 118 Valladolid | 10 | 17 | 58.82% | 72.08% | . 5 Atalanta | 15 | 24 | 62.50% | 72.00% | . 17 Brest | 2 | 6 | 33.33% | 71.92% | . 87 Nürnberg | 2 | 6 | 33.33% | 71.92% | . There&#39;s always going to be some variance involved in a stat like that, but there could be other factors at play as well: . # Data from https://www.transfermarkt.com/manchester-city/elfmeterschuetzen/verein/281 # KDB&#39;s estimate includes his miss against Liverpool man_city_career = {&#39;name&#39;: [&#39;Elano&#39;, &#39;Yaya Touré&#39;, &#39;Sergio Agüero&#39;, &#39;Carlos Tevez&#39;, &#39;Robinho&#39;, &#39;Mario Balotelli&#39;, &#39;James Milner&#39;, &#39;Raheem Sterling&#39;, &#39;Kevin De Bruyne&#39;, &#39;Gabriel Jesus&#39;, &#39;İlkay Gündoğan&#39;, &#39;Riyad Mahrez&#39;], &#39;penalties_scored&#39;: [23,15,47,24,12,38,30, 2,7,4,9,10], &#39;penalties_taken&#39;: [26,15,60,34,15,43,35, 4,9,10,10,16], &#39;align&#39;: [&#39;left&#39;, &#39;left&#39;, &#39;left&#39;, &#39;right&#39;, &#39;left&#39;, &#39;left&#39;, &#39;center&#39;, &#39;center&#39;, &#39;right&#39;, &#39;right&#39;, &#39;center&#39;, &#39;right&#39;], &#39;palette&#39;: [0,0,2,0,0,0,0, 2,2,2,1,2]} man_city = pd.DataFrame.from_dict(man_city_career) man_city = man_city.assign(predicted_conversion=predicted_conversion(man_city[&#39;penalties_scored&#39;], man_city[&#39;penalties_taken&#39;])).sort_values(by=&#39;predicted_conversion&#39;, ascending=False) # Create the main plot fig, ax = plt.subplots(figsize=(13,8)) ax.set(title=&#39;Hughes, Mancini and Pellegrini had far better options from the penalty spot than Pep Guardiola&#39;, ylim=[0, 27], xlabel=&#39;Predicted penalty conversion rate&#39;) ax.xaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1)) palette = sns.color_palette() sns.kdeplot(data=players[&#39;predicted_conversion&#39;], color=&#39;skyblue&#39;, fill=True, bw_adjust=3) # Add mean plt.axvline(players[&#39;predicted_conversion&#39;].mean(), 0, 27, c=&#39;skyblue&#39;, linestyle=&#39;--&#39;) for index, row in man_city.iterrows(): # Set line height to be proportional to number of penalties taken lineheight = row[&#39;penalties_taken&#39;]/players[&#39;penalties_taken&#39;].max() textheight = 27.5*lineheight plt.axvline(row[&#39;predicted_conversion&#39;], 0, lineheight, c=palette[row[&#39;palette&#39;]]) plt.text(row[&#39;predicted_conversion&#39;], textheight, row[&#39;name&#39;], c=palette[row[&#39;palette&#39;]], ha=row[&#39;align&#39;]) # Add rug sns.rugplot(data=players[&#39;predicted_conversion&#39;], color=&#39;skyblue&#39;, height=0.02) # Add legend custom_lines = [Line2D([0], [0], color=palette[0], lw=2.5), Line2D([0], [0], color=palette[2], lw=2.5), Line2D([0], [0], color=palette[1], lw=2.5), Line2D([0], [0], color=&#39;skyblue&#39;, lw=2.5, linestyle=&#39;--&#39;), Line2D([0], [0], color=&#39;skyblue&#39;, lw=2.5),] ax.legend(custom_lines, [&#39;Mansour era nbefore 16/17&#39;, &#39;Guardiola era&#39;, &#39;Current best&#39;, &#39;Average player&#39;, &#39;%d total players&#39; % (len(players))]) # Remove axes sns.despine(right=True, top=True); . . We can clearly see a big difference here pre/post Pep (with the exception of Carlos Tevez, who mainly took penalties in 09/10 after Elano left). In fact, the wealth of options meant that James Milner was rarely called upon to take penalties for City. Balotelli famously never needs to look at the ball when he takes a penalty - Joe Hart once said that his penalties were almost impossible to stop, which was far greater praise at the time than it would be now (sorry Joe!), and did a lap of honour when he finally saved one in training. To answer our earlier question, not only is Yaya Touré significantly better than Gabriel Jesus, they are on opposite ends of the scale! Jesus is great at many aspects of the game, but from the penalty spot he&#39;s one of the worst players I&#39;ve seen with a 70.15% predicted conversion rate. . # Plot the range of estimates for Yaya and Jesus fig, ax = plt.subplots(figsize=(9,6)) ax.set(title=&#39;Yaya Touré and Gabriel Jesus are probably not equally skilled at taking penalties&#39;, ylim=[0, 9], xlabel=&#39;Predicted penalty conversion rate&#39;) ax.xaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1)) # Yaya goals = 15 misses = 0 yaya_dist = ss.beta.rvs(alpha0+goals, beta0+misses, size=10000) sns.kdeplot(data=yaya_dist, color=palette[0], fill=True, bw_adjust=1.5) est1 = predicted_conversion(goals, goals+misses) plt.axvline(est1, 0, 0.95, c=palette[0], linestyle=&#39;--&#39;) # Jesus goals = 4 misses = 6 jesus_dist = ss.beta.rvs(alpha0+goals, beta0+misses, size=10000) sns.kdeplot(data=jesus_dist, color=&#39;skyblue&#39;, fill=True, bw_adjust=1.5) est2 = predicted_conversion(goals, goals+misses) plt.axvline(est2, 0, 0.95, c=&#39;skyblue&#39;, linestyle=&#39;--&#39;) # Add custom legend and axes custom_lines = [Line2D([0], [0], color=&#39;skyblue&#39;, lw=2.5), Line2D([0], [0], color=palette[0], lw=2.5)] ax.legend(custom_lines, [&#39;Jesus: %s&#39; % (str(round(est2*100, 1)))+&#39;%&#39;, &#39;Touré: %s&#39; % (str(round(est1*100, 1)))+&#39;%&#39;], loc=&#39;upper left&#39;) sns.despine(right=True, top=True); . . Aside from his well publicised disagreements with Touré it&#39;s hard to blame Pep too much, since it appears his current squad are good at everything but penalties. İlkay Gündoğan&#39;s miss came at a time when City had already missed three of their last five so we can certainly speculate that there would have been a lot of pressure to change things; in fact as I alluded to earlier things got so bad that Pep was seriously considering putting Ederson in charge of spot kicks. De Bruyne&#39;s miss against Liverpool bumped his estimate down to about league average, but he was still predicted to be a bit worse than Gündoğan before that: . # Plot the range of estimates for KDB before and after his penalty against Liverpool fig, ax = plt.subplots(figsize=(9,6)) ax.set(title=&quot;De Bruyne&#39;s predicted conversion rate decreased after his miss against Liverpool&quot;, ylim=[0, 9], xlabel=&#39;Predicted penalty conversion rate&#39;) ax.xaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1)) # Before Liverpool penalty goals = 7 misses = 1 kdb_dist = ss.beta.rvs(alpha0+goals, beta0+misses, size=10000) sns.kdeplot(data=kdb_dist, color=&#39;skyblue&#39;, fill=True, bw_adjust=1.5) est1 = predicted_conversion(goals, goals+misses) plt.axvline(est1, 0, 0.95, c=&#39;skyblue&#39;, linestyle=&#39;--&#39;) # After Liverpool penalty misses = 2 kdb_dist = ss.beta.rvs(alpha0+goals, beta0+misses, size=10000) sns.kdeplot(data=kdb_dist, color=palette[0], bw_adjust=1.5) est2 = predicted_conversion(goals, goals+misses) plt.axvline(est2, 0, 0.95, c=palette[0], linestyle=&#39;--&#39;) # Add custom legend and axes custom_lines = [Line2D([0], [0], color=palette[0], lw=2.5), Line2D([0], [0], color=&#39;skyblue&#39;, lw=2.5)] ax.legend(custom_lines, [&#39;New estimate: %s&#39; % (str(round(est2*100, 1)))+&#39;%&#39;, &#39;Old estimate: %s&#39; % (str(round(est1*100, 1)))+&#39;%&#39;], loc=&#39;upper left&#39;) sns.despine(right=True, top=True); . . İlkay Gündoğan is at the 92.2th percentile of 2204 players in the dataset with a predicted penalty conversion rate of 80.22%! . This analysis suggests Gündoğan deserves another go, and I&#39;d like to see him given the nod the next time he&#39;s on the pitch. We aren&#39;t talking about a massive difference between the two players, but why not take edges anywhere you can, even if they are small ones? We have to assume Ederson is worse than Gündoğan as well since we have no additional data, but if Ederson really is City&#39;s best penalty taker then why not use him - it can&#39;t really get much worse at this point! . Why isn&#39;t Aleksandar Mitrovi&#263; taking penalties for Fulham? . Antonin Panenka (83.5% predicted conversion rate) might not have been too pleased with the result of Ademola Lookman&#39;s botched attempt against West Ham last weekend. Lookman was heavily criticised, and at the time I was wondering why Aleksandar Mitrović wasn&#39;t the one taking the penalty. Now I know why: . fulham_career = {&#39;name&#39;: [&#39;Aleksandar Mitrović&#39;, &#39;Tom Cairney&#39;, &#39;Ivan Cavaleiro&#39;, &#39;Ademola Lookman n(before miss)&#39;], &#39;penalties_scored&#39;: [15,2,6,0], &#39;penalties_taken&#39;: [22,3,7,0]} fulham = pd.DataFrame.from_dict(fulham_career) fulham = fulham.assign(predicted_conversion=predicted_conversion(fulham[&#39;penalties_scored&#39;], fulham[&#39;penalties_taken&#39;])).sort_values(by=&#39;predicted_conversion&#39;, ascending=False) fulham[&#39;penalties_missed&#39;] = fulham[&#39;penalties_taken&#39;] - fulham[&#39;penalties_scored&#39;] dist_df = pd.DataFrame() for index, row in fulham.iterrows(): dist = ss.beta.rvs(alpha0+row[&#39;penalties_scored&#39;], beta0+row[&#39;penalties_missed&#39;], size=10000) temp = pd.DataFrame({&#39;predicted_conversion&#39;: dist}) temp[&#39;name&#39;] = row[&#39;name&#39;] dist_df = dist_df.append(temp) fig, ax = plt.subplots(figsize=(10,6)) ax.set(title=&quot;It&#39;s not surprising that Aleksandar Mitrović isn&#39;t taking penalties for Fulham&quot;) ax.xaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1)) sns.violinplot(data=dist_df, x=&#39;predicted_conversion&#39;, y=&#39;name&#39;, palette=&#39;light:dimgrey&#39;, inner=&#39;quart&#39;, orient=&#39;h&#39;, ax=ax) plt.xlabel(&#39;Predicted penalty conversion rate&#39;) plt.ylabel(&#39;&#39;) sns.despine(right=True, top=True); . . Aleksandar Mitrović is at the 3.8th percentile of 2204 players in the dataset with a predicted penalty conversion rate of 74.34%! . It&#39;s a good job Mitrović isn&#39;t first choice! Cavaleiro appears to be the best candidate by our estimate, but maybe Lookman showed something in training that set him apart from the rest - the Fulham coaches will have seen him take a lot more penalties than we have. Going for a &#39;Panenka&#39; on your first attempt certainly suggests that you at least rate your own ability from the spot pretty highly, although if we use that logic maybe we should be recommending John Stones as City&#39;s go-to option... . Simulating the Euro 96 semi-final shootout . At this point it seems inevitable to most England fans that every major tournament will end in a penalty shootout loss to Germany in the semis. . . Let&#39;s have a look at one example, the Euro 96 shootout, and see whether that&#39;s really the case. . # https://www.transfermarkt.com/spielbericht/index/spielbericht/935928 eng_career = {&#39;name&#39;: [&#39;Alan Shearer&#39;, &#39;Teddy Sheringham&#39;, &#39;Steve McManaman&#39;, &#39;Paul Ince&#39;, &#39;David Platt&#39;, &#39;Paul Gascoigne&#39;, &#39;Darren Anderton&#39;, &#39;Gareth Southgate&#39;, &#39;Tony Adams&#39;, &#39;Stuart Pearce&#39;, &#39;David Seaman&#39;, &#39;Robbie Fowler&#39;], &#39;penalties_scored&#39;: [65,30,0,0,13, 1,6,0,0,10, 0,32], &#39;penalties_taken&#39;: [67,33,0,0,15, 1,6,0,0,10, 0,34], &#39;notes&#39;: [None, None, None, None, None, None, None, None, None, None, None, &#39;bench, not used&#39;]} ger_career = {&#39;name&#39;: [&#39;Stefan Kuntz&#39;, &#39;Mehmet Scholl&#39;, &#39;Andreas Möller&#39;, &#39;Christian Ziege&#39;, &#39;Dieter Eilts&#39;, &#39;Stefan Reuter&#39;, &#39;Matthias Sammer&#39;, &#39;Markus Babbel&#39;, &#39;Andreas Köpke&#39;, &#39;Thomas Strunz&#39;, &#39;Thomas Häßler&#39;, &#39;Marco Bode&#39;, &#39;Oliver Bierhoff&#39;], &#39;penalties_scored&#39;: [34,14,9,2,8, 10,0,0,2,4, 26,0,15], &#39;penalties_taken&#39;: [39,17,13,3,8, 15,0,0,2,5, 28,1,20], &#39;notes&#39;: [None, &quot;subbed off 77&#39;&quot;, None, None, None, None, None, None, None, &quot;subbed on 118&#39;&quot;, &quot;subbed on 77&#39;&quot;, &quot;subbed on 110&#39;&quot;, &quot;bench, not used&quot;]} england = pd.DataFrame.from_dict(eng_career) england = england.assign(predicted_conversion=predicted_conversion(england[&#39;penalties_scored&#39;], england[&#39;penalties_taken&#39;])).sort_values(by=&#39;predicted_conversion&#39;, ascending=False) germany = pd.DataFrame.from_dict(ger_career) germany = germany.assign(predicted_conversion=predicted_conversion(germany[&#39;penalties_scored&#39;], germany[&#39;penalties_taken&#39;])).sort_values(by=&#39;predicted_conversion&#39;, ascending=False) england . . name penalties_scored penalties_taken notes predicted_conversion . 0 Alan Shearer | 65 | 67 | None | 89.86% | . 11 Robbie Fowler | 32 | 34 | bench, not used | 85.31% | . 1 Teddy Sheringham | 30 | 33 | None | 83.73% | . 9 Stuart Pearce | 10 | 10 | None | 82.24% | . 6 Darren Anderton | 6 | 6 | None | 80.68% | . 4 David Platt | 13 | 15 | None | 80.20% | . 5 Paul Gascoigne | 1 | 1 | None | 78.31% | . 2 Steve McManaman | 0 | 0 | None | 77.76% | . 3 Paul Ince | 0 | 0 | None | 77.76% | . 7 Gareth Southgate | 0 | 0 | None | 77.76% | . 8 Tony Adams | 0 | 0 | None | 77.76% | . 10 David Seaman | 0 | 0 | None | 77.76% | . It looks like England actually had some good penalty takers available, particularly Shearer who has one of the highest predicted conversion rates we have found so far. Robbie Fowler was still young at the time, but it&#39;s notable that England didn&#39;t choose to bring him on just before the shootout despite having three substitutions remaining, since he was prolific from the spot later in his career. . name penalties_scored penalties_taken notes predicted_conversion . 10 Thomas Häßler | 26 | 28 | subbed on 77&#39; | 84.01% | . 0 Stefan Kuntz | 34 | 39 | None | 82.43% | . 4 Dieter Eilts | 8 | 8 | None | 81.49% | . 1 Mehmet Scholl | 14 | 17 | subbed off 77&#39; | 79.14% | . 8 Andreas Köpke | 2 | 2 | None | 78.83% | . 9 Thomas Strunz | 4 | 5 | subbed on 118&#39; | 78.01% | . 6 Matthias Sammer | 0 | 0 | None | 77.76% | . 7 Markus Babbel | 0 | 0 | None | 77.76% | . 3 Christian Ziege | 2 | 3 | None | 76.98% | . 12 Oliver Bierhoff | 15 | 20 | bench, not used | 76.83% | . 11 Marco Bode | 0 | 1 | subbed on 110&#39; | 75.85% | . 2 Andreas Möller | 9 | 13 | None | 75.65% | . 5 Stefan Reuter | 10 | 15 | None | 74.71% | . Germany did make some substitutions however, bringing their best penalty taker Thomas Häßler on in normal time in addition to Marco Bode and Thomas Strunz in extra time. Whilst Bode (a winger) looks worse than average at penalties he was subbed on for a centre-back in an attempt to win the game in extra-time, and he wasn&#39;t chosen as one of the top six options in the shootout. It&#39;s interesting that Thomas Strunz was brought on to take the second penalty in favour of Oliver Bierhoff (who scored twice in the final), since our estimate is that Bierhoff is below average from the spot. Maybe the coaches were onto something... Captain Andreas Möller scored the winning penalty in sudden-death, but it looks like he was probably a below average penalty taker also. . Note: Just a reminder that I&#8217;m still ignoring goalkeeper skill, but Andreas Köpke saved 22/84 penalties in his career, so maybe it&#8217;s harder to score against him than a typical goalie! . # Remove unwanted players fowler = england.copy()[england[&#39;name&#39;]==&#39;Robbie Fowler&#39;] england = england.copy()[england[&#39;name&#39;]!=&#39;Robbie Fowler&#39;] germany = germany.copy()[~germany[&#39;name&#39;].isin([&#39;Mehmet Scholl&#39;, &#39;Oliver Bierhoff&#39;])] # Order the players to get Platt taking the second penalty etc # We only know the first six players for each team, so assume the order for the rest england[&#39;order&#39;] = [1,5,3,7,2,4,8,9,6,10,11] england = england.copy().sort_values(&#39;order&#39;) germany[&#39;order&#39;] = [1,5,7,8,2,9,10,4,11,6,3] germany = germany.copy().sort_values(&#39;order&#39;) . . We can see which team is expected to win the shootout by simulating it using the predicted conversion rates for each player to determine whether they scored or missed their penalty. Here is one simulation: . def shootout(team_a, team_b, printer=False): &quot;&quot;&quot;Function to simulate a penalty shootout. Takes two dataframes as input, one for each team. The dataframe should be sorted in the order used for the shootout, i.e. the first player to take a penalty should be at row 1, the second at row 2 etc. &quot;&quot;&quot; a_score = 0 b_score = 0 a_wins = 0 b_wins = 0 a_index = 0 b_index = 0 # df index should be from 0 to len(df) team_a = team_a.reset_index().drop(&#39;index&#39;, axis=1) team_b = team_b.reset_index().drop(&#39;index&#39;, axis=1) while a_wins == b_wins: # Reset index to 0 if every player has taken a penalty in this round if a_index &gt; len(team_a)-1: a_index = 0 if b_index &gt; len(team_b)-1: b_index = 0 # Get Team A result a_player = team_a.iloc[a_index, 0] a_prob = team_a.iloc[a_index, 4] a_result = np.random.choice([0,1], 1, p=[1-a_prob, a_prob]) a_score += a_result if printer != False: print(a_player+&#39;...scores! (%d-%d)&#39; % (a_score, b_score) if a_result ==1 else a_player+&#39;...misses! (%d-%d)&#39; % (a_score, b_score)) # Get Team B result b_player = team_b.iloc[a_index, 0] b_prob = team_b.iloc[a_index, 4] b_result = np.random.choice([0,1], 1, p=[1-a_prob, a_prob]) b_score += b_result if printer != False: print(b_player+&#39;...scores! (%d-%d)&#39; % (a_score, b_score) if b_result ==1 else b_player+&#39;...misses! (%d-%d)&#39; % (a_score, b_score)) a_index += 1 b_index += 1 # Stop the shootout when scores are no longer equal and at least five penalties each have been taken if (a_index &gt;= 5): if (a_score &gt; b_score): a_wins += 1 if printer != False: print(&#39; nTeam A wins! (%d-%d)&#39; % (a_score, b_score)) elif (a_score &lt; b_score): b_wins += 1 if printer != False: print(&#39; nTeam B wins! (%d-%d)&#39; % (b_score, a_score)) return a_wins, b_wins # Run one penalty shootout _, _ = shootout(england, germany, printer=True) . . Alan Shearer...scores! (1-0) Thomas Häßler...misses! (1-0) David Platt...scores! (2-0) Thomas Strunz...scores! (2-1) Stuart Pearce...scores! (3-1) Stefan Reuter...scores! (3-2) Paul Gascoigne...scores! (4-2) Christian Ziege...scores! (4-3) Teddy Sheringham...misses! (4-3) Stefan Kuntz...scores! (4-4) Gareth Southgate...misses! (4-4) Andreas Möller...misses! (4-4) Darren Anderton...scores! (5-4) Dieter Eilts...misses! (5-4) Team A wins! (5-4) . Let&#39;s run this thousands of times and calculate how often England would be expected to advance to the final: . num_sims = 5000 def simulate_shootouts(team_a, team_b, num_sims): a_wins = 0 b_wins = 0 for i in range(num_sims): a, b = shootout(team_a, team_b) a_wins += a b_wins += b return a_wins, b_wins eng_wins, ger_wins = simulate_shootouts(england, germany, num_sims) eng_win_pct = str(round((eng_wins/num_sims)*100, 1)) print(&#39;England win probability = %s&#39; % (eng_win_pct+&#39;%&#39;)) . . England win probability = 51.4% . Pretty close, but a loss wasn&#39;t inevitable at least! Unless you believe in curses, that is... . Conclusion . Thanks for reading! I hope you enjoyed this and learned something useful. We could have made a much more complicated model of penalty taking skill, but as discussed earlier extra complexity wouldn&#39;t necessarily be better here. By using empirical Bayes estimation we were able to get some interesting insights out of a limited dataset in just a few steps. If you want to explore this topic further you could use the same process to estimate penalty save percentage, or you could try to improve on this model. A couple of ways to do that would be to use more data or estimate different priors for different groups of players, e.g. should the prior distribution for a team&#39;s main penalty taker be the same as the prior for someone who was only trusted to take a handful of penalties in their career? Let me know what you find out! . Thanks again to David Robinson, whose work make this possible, and to FBRef and Transfermarkt for the data. .",
            "url": "https://www.thomaswhelan.com/bayes/football/visualisation/2020/11/14/evaluating-penalty-takers-using-empirical-bayes.html",
            "relUrl": "/bayes/football/visualisation/2020/11/14/evaluating-penalty-takers-using-empirical-bayes.html",
            "date": " • Nov 14, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "COVID-19 Vaccine Tweet Sentiment Analysis with fastai - Part 1",
            "content": "Introduction . In this post we will create a model to perform sentiment analysis on tweets about COVID-19 vaccines using the fastai library. I will provide a brief overview of the process here, but a much more in-depth explanation of NLP with fastai can be found in lesson 8 of the fastai course. For convenience clicking on inline code written like this will take you to the relevant part of the fastai documentation where appropriate. In part 2 we will use the model for analysis, looking at changes in tweet sentiment over time and how that relates to the progress of vaccination in different countries. . Transfer learning in NLP - the ULMFiT approach . We will be making use of transfer learning to help us create a model to analyse tweet sentiment. The idea behind transfer learning is that neural networks learn information that generalises to new problems, particularly the early layers of the network. In computer vision, for example, we can take a model that was trained on the ImageNet dataset to recognise different features of images such as circles, then apply that to a smaller dataset and fine-tune the model to be more suited to a specific task (e.g. classifying images as cats or dogs). This technique allows us to train neural networks much faster and with far less data than we would otherwise need. . In 2018 a paper introduced a transfer learning technique for NLP called &#39;Universal Language Model Fine-Tuning&#39; (ULMFiT). The approach is as follows: . Train a language model to predict the next word in a sentence. This step is already done for us; with fastai we can download a model that has been pre-trained for this task on millions of Wikipedia articles. A good language model already knows a lot about how language works in general - for instance, given the sentence &#39;Tokyo is the capital of&#39;, the model might predict &#39;Japan&#39; as the next word. In this case the model understands that Tokyo is closely related to Japan and that &#39;capital&#39; refers to &#39;city&#39; here instead of &#39;upper-case&#39; or &#39;money&#39;. | Fine-tune the language model to a more specific task. The pre-trained language model is good at understanding Wikipedia English, but Twitter English is a bit different. We can take the information the Wikipedia model has learned and apply that to a Twitter dataset to get a Twitter language model that is good at predicting the next word in a tweet. | Fine-tune a classification model to identify sentiment using the pre-trained language model. The idea here is that since our language model already knows a lot about Twitter English, it&#39;s not a huge leap from there to train a classifier that understands that &#39;love&#39; refers to positive sentiment and &#39;hate&#39; refers to negative sentiment. If we tried to train a classifier without using a pre-trained model it would have to learn the whole language from scratch first, which would be very difficult and time consuming. | . This notebook will walk through steps 2 and 3 with fastai. We will then apply the model to unlabelled COVID-19 vaccine tweets and save the results for analysis in part 2. . Important: You will need a GPU to train models with fastai, but fortunately for us Google Colab provides us with access to one for free! To use it, select &#8217;Runtime&#8217; from the menu at the top of the notebook, then &#8217;Change runtime type&#8217;, and ensure your hardware accelerator is set to &#8217;GPU&#8217; before continuing! . Data preparation . This is a write-up of a submission I made for several Kaggle tasks. The tasks are still open and accepting new entries at the time of writing if you want to enter as well! On Kaggle the data is already readily available when using their notebook servers; however, we are using Google Colab today, so we will need to access the Kaggle API to download the data. . Note: Kaggle also have free GPU credits if you prefer to work on their notebook servers instead. . Getting the data from Kaggle . The first step is to create an API token. To do this, the steps are as follows: . Go to &#39;Account&#39; on Kaggle and scroll down to the &#39;API&#39; section. | Expire all current API tokens by clicking &#39;Expire API Token&#39;. | Click &#39;Create New API Token&#39;, which will automatically download a file called kaggle.json. | Upload the kaggle.json file using the file uploader widget below. | # See https://neptune.ai/blog/google-colab-dealing-with-files for more tips on working with files in Colab from google.colab import files uploaded = files.upload() . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json . Next, we need to install the Kaggle API. . Note: The API is already preinstalled in Google Colab, but sometimes it&#8217;s an outdated version, so it&#8217;s best to upgrade it in case. . !pip uninstall -q -y kaggle !pip install -q --upgrade pip !pip install -q --upgrade kaggle . |████████████████████████████████| 1.5MB 5.4MB/s |████████████████████████████████| 58 kB 2.8 MB/s Building wheel for kaggle (setup.py) ... done . The API docs tell us that we need to ensure kaggle.json is in the location ~/.kaggle/kaggle.json, so let&#39;s make the directory and move the file. . # https://www.machinelearningmindset.com/kaggle-dataset-in-google-colab/ !mkdir -p ~/.kaggle !cp kaggle.json ~/.kaggle/ # Check the file in its new directory !ls /root/.kaggle/ # Check the file permission !ls -l ~/.kaggle/kaggle.json #Change the file permission # chmod 600 file – owner can read and write # chmod 700 file – owner can read, write and execute !chmod 600 ~/.kaggle/kaggle.json . kaggle.json -rw-r--r-- 1 root root 63 Mar 17 15:35 /root/.kaggle/kaggle.json . Now we can download the data using !kaggle dataset download -d username-of-dataset-creator/name-of-dataset. . Note: There is also an API download command on the dataset page that you can copy/paste instead. . # We will be using two datasets for this part, as well as a third dataset for part 2 # To save time in part 2 I&#39;m going to download them all now and save locally !kaggle datasets download -d gpreda/all-covid19-vaccines-tweets !kaggle datasets download -d maxjon/complete-tweet-sentiment-extraction-data !kaggle datasets download -d gpreda/covid-world-vaccination-progress . Downloading all-covid19-vaccines-tweets.zip to /content 0% 0.00/4.76M [00:00&lt;?, ?B/s] 100% 4.76M/4.76M [00:00&lt;00:00, 156MB/s] Downloading complete-tweet-sentiment-extraction-data.zip to /content 0% 0.00/2.58M [00:00&lt;?, ?B/s] 100% 2.58M/2.58M [00:00&lt;00:00, 148MB/s] Downloading covid-world-vaccination-progress.zip to /content 0% 0.00/146k [00:00&lt;?, ?B/s] 100% 146k/146k [00:00&lt;00:00, 61.1MB/s] . The files will be downloaded in .zip format, so let&#39;s unzip them. . # To unzip you can use the following: #!mkdir folder_name #!unzip anyfile.zip -d folder_name # Or unzip all !unzip -q *.zip . 3 archives were successfully processed. . Loading and cleaning the data . As with kaggle, an older version of fastai is preinstalled in Colab, so we will need to upgrade it first. . Important: Make a note of the fastai version you are using, since any models you create and save will need to be run using the same version later. . ! [ -e /content ] &amp;&amp; pip install -Uqq fastai # upgrade fastai on colab import fastai; fastai.__version__ . |████████████████████████████████| 193 kB 4.1 MB/s |████████████████████████████████| 776.8 MB 18 kB/s |████████████████████████████████| 12.8 MB 23 kB/s |████████████████████████████████| 53 kB 1.4 MB/s ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. torchtext 0.9.0 requires torch==1.8.0, but you have torch 1.7.1 which is incompatible. . &#39;2.2.7&#39; . Let&#39;s import fastai&#39;s text module and take a look at our data. . Tip: If you use import *, useful libraries like pandas and numpy will also be imported at the same time! . from fastai.text.all import * . vax_tweets = pd.read_csv(&#39;vaccination_all_tweets.csv&#39;) vax_tweets[[&#39;date&#39;, &#39;text&#39;, &#39;hashtags&#39;, &#39;user_followers&#39;]].head() . date text hashtags user_followers . 0 2020-12-20 06:06:44 | Same folks said daikon paste could treat a cytokine storm #PfizerBioNTech https://t.co/xeHhIMg1kF | [&#39;PfizerBioNTech&#39;] | 405 | . 1 2020-12-13 16:27:13 | While the world has been on the wrong side of history this year, hopefully, the biggest vaccination effort we&#39;ve ev… https://t.co/dlCHrZjkhm | NaN | 834 | . 2 2020-12-12 20:33:45 | #coronavirus #SputnikV #AstraZeneca #PfizerBioNTech #Moderna #Covid_19 Russian vaccine is created to last 2-4 years… https://t.co/ieYlCKBr8P | [&#39;coronavirus&#39;, &#39;SputnikV&#39;, &#39;AstraZeneca&#39;, &#39;PfizerBioNTech&#39;, &#39;Moderna&#39;, &#39;Covid_19&#39;] | 10 | . 3 2020-12-12 20:23:59 | Facts are immutable, Senator, even when you&#39;re not ethically sturdy enough to acknowledge them. (1) You were born i… https://t.co/jqgV18kch4 | NaN | 49165 | . 4 2020-12-12 20:17:19 | Explain to me again why we need a vaccine @BorisJohnson @MattHancock #whereareallthesickpeople #PfizerBioNTech… https://t.co/KxbSRoBEHq | [&#39;whereareallthesickpeople&#39;, &#39;PfizerBioNTech&#39;] | 152 | . We could use the text column of this dataset to train a Twitter language model, but since our end goal is sentiment analysis we will need to find another dataset that also contains sentiment labels to train our classifier. Let&#39;s use &#39;Complete Tweet Sentiment Extraction Data&#39;, which contains 40,000 tweets labelled as either negative, neutral or positive sentiment. For more accurate results you could use the &#39;sentiment140&#39; dataset instead, which contains 1.6m tweets labelled as either positive or negative. . tweets = pd.read_csv(&#39;tweet_dataset.csv&#39;) tweets[[&#39;old_text&#39;, &#39;new_sentiment&#39;]].head() . old_text new_sentiment . 0 @tiffanylue i know i was listenin to bad habit earlier and i started freakin at his part =[ | NaN | . 1 Layin n bed with a headache ughhhh...waitin on your call... | negative | . 2 Funeral ceremony...gloomy friday... | negative | . 3 wants to hang out with friends SOON! | positive | . 4 @dannycastillo We want to trade with someone who has Houston tickets, but no one will. | neutral | . For our language model, the only input we need is the tweet text. As we will see in a moment fastai can handle text preprocessing and tokenization for us, but it might be a good idea to remove things like twitter handles, urls, hashtags and emojis first. You could experiment with leaving these in for your own models and see how it affects the results. There are also some rows with blank tweets which need to be removed. . We ideally want the language model to learn not just about tweet language, but more specifically about vaccine tweet language. We can therefore use text from both datasets as input for the language model. For the classification model we need to remove all rows with missing sentiment, however. . def de_emojify(inputString): return inputString.encode(&#39;ascii&#39;, &#39;ignore&#39;).decode(&#39;ascii&#39;) # Code via https://www.kaggle.com/pawanbhandarkar/generate-smarter-word-clouds-with-log-likelihood def tweet_proc(df, text_col=&#39;text&#39;): df[&#39;orig_text&#39;] = df[text_col] # Remove twitter handles df[text_col] = df[text_col].apply(lambda x:re.sub(&#39;@[^ s]+&#39;,&#39;&#39;,x)) # Remove URLs df[text_col] = df[text_col].apply(lambda x:re.sub(r&quot;http S+&quot;, &quot;&quot;, x)) # Remove emojis df[text_col] = df[text_col].apply(de_emojify) # Remove hashtags df[text_col] = df[text_col].apply(lambda x:re.sub(r&#39; B# S+&#39;,&#39;&#39;,x)) return df[df[text_col]!=&#39;&#39;] # Clean the text data and combine the dfs tweets = tweets[[&#39;old_text&#39;, &#39;new_sentiment&#39;]].rename(columns={&#39;old_text&#39;:&#39;text&#39;, &#39;new_sentiment&#39;:&#39;sentiment&#39;}) vax_tweets[&#39;sentiment&#39;] = np.nan tweets = tweet_proc(tweets) vax_tweets = tweet_proc(vax_tweets) df_lm = tweets[[&#39;text&#39;, &#39;sentiment&#39;]].append(vax_tweets[[&#39;text&#39;, &#39;sentiment&#39;]]) df_clas = df_lm.dropna(subset=[&#39;sentiment&#39;]) print(len(df_lm), len(df_clas)) . 70732 31323 . df_clas.head() . text sentiment . 1 Layin n bed with a headache ughhhh...waitin on your call... | negative | . 2 Funeral ceremony...gloomy friday... | negative | . 3 wants to hang out with friends SOON! | positive | . 4 We want to trade with someone who has Houston tickets, but no one will. | neutral | . 5 Re-pinging why didn&#39;t you go to prom? BC my bf didn&#39;t like my friends | negative | . Training a language model . To train our language model we can use self-supervised learning; we just need to give the model some text as an independent variable and fastai will automatically preprocess it and create a dependent variable for us. We can do this in one line of code using the DataLoaders class, which converts our input data into a DataLoader object that can be used as an input to a fastai Learner. . dls_lm = TextDataLoaders.from_df(df_lm, text_col=&#39;text&#39;, is_lm=True, valid_pct=0.1) . /usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray return array(a, dtype, copy=False, order=order) . Here we told fastai that we are working with text data, which is contained in the text column of a pandas DataFrame called df_lm. We set is_lm=True since we want to train a language model, so fastai needs to label the input data for us. Finally, we told fastai to hold out a random 10% of our data for a validation set using valid_pct=0.1. . Let&#39;s take a look at the first two rows of the DataLoader using show_batch. . dls_lm.show_batch(max_n=2) . text text_ . 0 xxbos xxup rip xxmaj big cup … i will miss you xxbos xxmaj morning do n&#39;t ask me why xxmaj i &#39;m up so early xxbos xxmaj swiss drugmaker to help make xxbos xxmaj roast was yummy , i think mum was impressed xxrep 3 ! xxbos tol xxrep 3 d you there was thunder ! ew now it &#39;s all rainy xxup d : i &#39;m scared ! xxbos thanks xxmaj | xxup rip xxmaj big cup … i will miss you xxbos xxmaj morning do n&#39;t ask me why xxmaj i &#39;m up so early xxbos xxmaj swiss drugmaker to help make xxbos xxmaj roast was yummy , i think mum was impressed xxrep 3 ! xxbos tol xxrep 3 d you there was thunder ! ew now it &#39;s all rainy xxup d : i &#39;m scared ! xxbos thanks xxmaj xxunk | . 1 prime minister for n xxmaj xxunk xxmaj xxunk . xxbos xxmaj thread : xxmaj as the rolls out the &amp; &amp; how s your state , ( district or xxunk xxbos xxmaj an hour of walking in hot weather = a satisfied but hurting xxmaj xxunk . xxmaj ow , blisters . xxbos awesome that s what i m xxunk the song paranoid . its stuck in my head ! and i | minister for n xxmaj xxunk xxmaj xxunk . xxbos xxmaj thread : xxmaj as the rolls out the &amp; &amp; how s your state , ( district or xxunk xxbos xxmaj an hour of walking in hot weather = a satisfied but hurting xxmaj xxunk . xxmaj ow , blisters . xxbos awesome that s what i m xxunk the song paranoid . its stuck in my head ! and i love | . We have a new column, text_, which is text offset by one. This is the dependent variable fastai created for us. By default fastai uses word tokenization, which splits the text on spaces and punctuation marks and breaks up words like can&#39;t into two separate tokens. fastai also has some special tokens starting with &#39;xx&#39; that are designed to make things easier for the model; for example xxmaj indicates that the next word begins with a capital letter and xxunk represents an unknown word that doesn&#39;t appear in the vocabulary very often. You could experiment with subword tokenization instead, which will split the text on commonly occuring groups of letters instead of spaces. This might help if you wanted to leave hashtags in since they often contain multiple words joined together with no spaces, e.g. #CovidVaccine. The fastai tokenization process is explained in much more detail here for those interested. . Fine-tuning the language model . The next step is to create a language model using language_model_learner. . learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, Perplexity()]).to_fp16() . Here we passed language_model_learner our DataLoaders, dls_lm, and the pre-trained RNN model, AWD_LSTM, which is built into fastai. drop_mult is a multiplier applied to all dropouts in the AWD_LSTM model to reduce overfitting. For example, by default fastai&#39;s AWD_LSTM applies EmbeddingDropout with 10% probability (at the time of writing), but we told fastai that we want to reduce that to 3%. The metrics we want to track are perplexity, which is the exponential of the loss (in this case cross entropy loss), and accuracy, which tells us how often our model predicts the next word correctly. We can also train with fp16 to use less memory and speed up the training process. . We can find a good learning rate for training using lr_find and use that to fit our model. . learn.lr_find() . SuggestedLRs(lr_min=0.04365158379077912, lr_steep=0.02754228748381138) . When we created our Learner the embeddings from the pre-trained AWD_LSTM model were merged with random embeddings added for words that weren&#39;t in the vocabulary. The pre-trained layers were also automatically frozen for us. Using fit_one_cycle with our Learner will train only the new random embeddings (i.e. words that are in our Twitter vocab but not the Wikipedia vocab) in the last layer of the neural network. . learn.fit_one_cycle(1, 3e-2) . epoch train_loss valid_loss accuracy perplexity time . 0 | 4.390779 | 4.256468 | 0.257898 | 70.560310 | 03:45 | . After one epoch our language model is predicting the next word in a tweet around 25% of the time - not too bad! We can unfreeze the entire model, find a more suitable learning rate and train for a few more epochs to improve the accuracy further. . learn.unfreeze() learn.lr_find() . SuggestedLRs(lr_min=0.0002511886414140463, lr_steep=7.585775847473997e-07) . learn.fit_one_cycle(4, 1e-3) . epoch train_loss valid_loss accuracy perplexity time . 0 | 3.960577 | 4.097842 | 0.279537 | 60.210228 | 04:20 | . 1 | 3.799337 | 4.013978 | 0.290340 | 55.366707 | 04:20 | . 2 | 3.624613 | 4.001914 | 0.295858 | 54.702751 | 04:19 | . 3 | 3.470943 | 4.027544 | 0.295395 | 56.122932 | 04:20 | . After a bit more training we can predict the next word in a tweet around 29% of the time. Let&#39;s test the model out by using it to write some random tweets (in this case it will generate some text following &#39;I love&#39;). . TEXT = &quot;I love&quot; N_WORDS = 30 N_SENTENCES = 2 print(&quot; n&quot;.join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES))) . i love it when your back is full ! i love it , and i liked it ! I &#39;m not talking about that to anyone else . i love this one Although i can see the difference in the way , I &#39;m sure i ca n&#39;t get it . first shot DONE ! . Some interesting results there! Let&#39;s save the model encoder so we can use it to fine-tune our classifier. The encoder is all of the model except for the final layer, which converts activations to probabilities of picking each token in the vocabulary. We want to keep the knowledge the model has learned about tweet language but we won&#39;t be using our classifier to predict the next word in a sentence, so we won&#39;t need the final layer any more. . learn.save_encoder(&#39;finetuned_lm&#39;) . Training a sentiment classifier . To get the DataLoaders for our classifier let&#39;s use the DataBlock API this time, which is more customisable. . dls_clas = DataBlock( blocks = (TextBlock.from_df(&#39;text&#39;, seq_len=dls_lm.seq_len, vocab=dls_lm.vocab), CategoryBlock), get_x=ColReader(&#39;text&#39;), get_y=ColReader(&#39;sentiment&#39;), splitter=RandomSplitter() ).dataloaders(df_clas, bs=64) . /usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray return array(a, dtype, copy=False, order=order) . To use the API, fastai needs the following: . blocks: TextBlock: Our x variable will be text contained in a pandas DataFrame. We want to use the same sequence length and vocab as the language model DataLoaders so we can make use of our pre-trained model. | CategoryBlock: Our y variable will be a single-label category (negative, neutral or positive sentiment). | . | get_x, get_y: Get data for the model by reading the text and sentiment columns from the DataFrame. | splitter: We will use RandomSplitter() to randomly split the data into a training set (80% by default) and a validation set (20%). | dataloaders: Builds the DataLoaders using the DataBlock template we just defined, the df_clas DataFrame and a batch size of 64. | . We can call show batch as before; this time the dependent variable is sentiment. . dls_clas.show_batch(max_n=2) . text category . 0 xxbos xxup pirate xxup voice : xxrep 3 a xxrep 3 r xxrep 3 g xxrep 3 h xxrep 3 ! i 4got xxup my xxup damn xxup wallet xxup at xxup work xxup xxunk xxrep 3 ! xxup dammit xxrep 3 ! xxup so xxup close xxup yet xxup so xxup far xxrep 3 ! xxup now xxup i m xxup starving xxrep 3 ! | negative | . 1 xxbos xxup ugg xxup want xxup to xxup go xxup to xxup xxunk xxup house xxup but i xxup ca nt xxup finna xxup be xxup bored xxup this xxup weekend xxrep 3 ! xxrep 3 u xxup xxunk xxup wanna xxup spend xxup da xxup nite xxup and xxup go xxup see xxup up xxup and xxup go xxup shopping | neutral | . Initialising the Learner is similar to before, but in this case we want a text_classifier_learner. . learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, metrics=accuracy).to_fp16() . Finally, we want to load the encoder from the language model we trained earlier, so our classifier uses pre-trained weights. . learn = learn.load_encoder(&#39;finetuned_lm&#39;) . Fine-tuning the classifier . Now we can train the classifier using discriminative learning rates and gradual unfreezing, which has been found to give better results for this type of model. First let&#39;s freeze all but the last layer: . learn.fit_one_cycle(1, 3e-2) . epoch train_loss valid_loss accuracy time . 0 | 0.828995 | 0.759167 | 0.666028 | 00:54 | . Now freeze all but the last two layers: . learn.freeze_to(-2) learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2)) . epoch train_loss valid_loss accuracy time . 0 | 0.733606 | 0.615954 | 0.739144 | 00:56 | . Now all but the last three: . learn.freeze_to(-3) learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3)) . epoch train_loss valid_loss accuracy time . 0 | 0.650302 | 0.566739 | 0.763570 | 01:07 | . Finally, let&#39;s unfreeze the entire model and train a bit more: . learn.unfreeze() learn.fit_one_cycle(3, slice(1e-3/(2.6**4),1e-3)) . epoch train_loss valid_loss accuracy time . 0 | 0.606317 | 0.567328 | 0.767401 | 01:23 | . 1 | 0.558857 | 0.560174 | 0.766762 | 01:24 | . 2 | 0.527293 | 0.562808 | 0.766922 | 01:24 | . learn.save(&#39;classifier&#39;) . Path(&#39;models/classifier.pth&#39;) . Our model correctly predicts sentiment around 77% of the time. We could perhaps do better with a larger dataset as mentioned earlier, or different model hyperparameters. It might be worth experimenting with this yourself to see if you can improve the accuracy. . We can quickly sense check the model by calling predict, which returns the predicted sentiment, the index of the prediction and predicted probabilities for negative, neutral and positive sentiment. . learn.predict(&quot;I love&quot;) . (&#39;positive&#39;, tensor(2), tensor([0.0025, 0.0041, 0.9934])) . learn.predict(&quot;I hate&quot;) . (&#39;negative&#39;, tensor(0), tensor([0.9889, 0.0071, 0.0040])) . Classifying unlabelled tweets . To carry out sentiment analysis on the vaccine tweets, we can add them to the DataLoaders as a test set: . pred_dl = dls_clas.test_dl(vax_tweets[&#39;text&#39;]) . We can then make predictions using get_preds: . preds = learn.get_preds(dl=pred_dl) . Finally, we can save the results for analysis later. . vax_tweets[&#39;sentiment&#39;] = preds[0].argmax(dim=-1) vax_tweets[&#39;sentiment&#39;] = vax_tweets[&#39;sentiment&#39;].map({0:&#39;negative&#39;, 1:&#39;neutral&#39;, 2:&#39;positive&#39;}) # Convert dates vax_tweets[&#39;date&#39;] = pd.to_datetime(vax_tweets[&#39;date&#39;], errors=&#39;coerce&#39;).dt.date # Save to csv vax_tweets.to_csv(&#39;vax_tweets_inc_sentiment.csv&#39;) . Conclusion . fastai make NLP really easy, and we were able to get quite good results with a limited dataset and not a lot of training time by using the ULMFiT approach. To summarise, the steps are: . Fine-tune a language model to predict the next word in a tweet, using a model pre-trained on Wikipedia. | Fine-tune a classification model to predict tweet sentiment using the pre-trained language model. | Apply the classifier to unlabelled tweets to analyse sentiment. | In part 2 we will use our new model for analysis, investigating the overall sentiment of each vaccine, how sentiment changes over time and the relationship between sentiment and vaccination progress in different countries. . I hope you found this useful, and thanks very much to Gabriel Preda for providing the data! . 1. Cover image via https://www.analyticsvidhya.com/blog/2018/07/hands-on-sentiment-analysis-dataset-python/↩ .",
            "url": "https://www.thomaswhelan.com/fastai/nlp/sentiment%20analysis/pytorch/2020/03/17/covid-19-vaccine-tweet-sentiment-analysis-with-fastai-part-1.html",
            "relUrl": "/fastai/nlp/sentiment%20analysis/pytorch/2020/03/17/covid-19-vaccine-tweet-sentiment-analysis-with-fastai-part-1.html",
            "date": " • Mar 17, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "👤 About Me",
          "content": "Tom Whelan . tom@thomaswhelan.com · @tom_whelan · twhelan22 I created this page to write about various data science and machine learning projects I have worked on. Previously I wrote a series teaching machine learning with Python through a fantasy football lens, which can be found at [fantasyfutopia.com](http://www.fantasyfutopia.com/python-for-fantasy-football-introduction/). .",
          "url": "https://www.thomaswhelan.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.thomaswhelan.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}